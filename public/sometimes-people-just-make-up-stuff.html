<!DOCTYPE html>
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="robots" content="index,follow,archive">
<meta name="description" content="Trust, and verify. Sometimes people just make up stuff because the facts don't fit the story they want to tell you.">
<title>A History | Computer Language Benchmarks Game</title>
<link rel="shortcut icon" href="./favicon.ico">
<style><!-- 
a{color:black;text-decoration:none}article,footer,header{margin:auto;max-width:31em;width:92%}body{font:100% Droid Sans,Ubuntu,Verdana,sans-serif;margin:0;-webkit-text-size-adjust:100%}h3,h1,h2,table{font-family:Ubuntu Mono,Consolas,Menlo,monospace}footer{padding:2.6em 0 0}h3{font-size:1.4em;font-weight:700;margin:0;padding:.4em}h3,h3 a{color:white;background-color:#dd4814}h3 small{font-size:.64em}h1,h2{margin:1.5em 0 0}h1{font-size:1.4em;font-weight:400}h2{font-size:1.2em}p{color:#333;line-height:1.4;margin:.3em 0 0}p a{border-bottom:.1em solid #333;padding-bottom:.1em}@media only screen{th:nth-child(4),td:nth-child(4){display:none}}@media only screen and (min-width:33em){th:nth-child(4),td:nth-child(4){display:table-cell}}body{quotes:'\201C''\201D''\2018''\2019''\2039''\203A'}q:before{content:open-quote}q:after{content:close-quote}table{font-family:Menlo,Consolas,Ubuntu Monospace,Andale Mono,monospace;margin:.7em 0;text-align:right}td{border-bottom:.15em dotted #eee;padding:.7em .7em 0 0}td:first-child,th:first-child{text-align:left}th{font-weight:400;padding:0 .7em 0 0;text-align:left}@media only screen and (min-width:60em){article,footer,header{font-size:1.25em}}
--></style>
<header>
  <h3><a href="https://benchmarksgame-team.pages.debian.net/benchmarksgame/">The&nbsp;<small>Computer&nbsp;Language</small><br>Benchmarks&nbsp;Game</a></h3>
</header>
<article>
  <h1 id="verify">A History</h1>
  <section>
    <h2 id="once">Once upon a time&hellip;</h2>
    <p>Doug Bagley had a burst of crazy curiosity: <q><a href="https://web.archive.org/web/20010124090400/http://www.bagley.org/~doug/shootout/">When I started this project</a>, my goal was to compare all the major scripting languages. Then I started adding in some compiled languages for comparison&hellip;</q> 
    <p>That project was abandoned in 2002, restarted in 2004 by Brent Fulgham, continued from 2008 by Isaac Gouy, and interrupted in 2018 by the Debian Alioth hosting service EOL. Everything has changed; several times.
    <p>April 2017 through March 2018, Google Analytics saw 477,419 users.
    <p>Enough that many web search results show web spam - be careful!
  </section>
  <h1 id="dismiss">Dismiss, Distract</h1>
  <section>
    <h2></h2>
    <p>You will probably come across stuff that people have said about the benchmarks game. Did they show that what they claim is true? If they provided a URL, does the content actually confirm what they said?
    <p>Perhaps they were genuinely mistaken. Perhaps the content changed.
  </section>
  <section>
    <h2 id="heard"><q>I heard that one is pretty bad&hellip;</q></h2>
    <p>Perhaps they were told wrong.
  </section>
  <section>
    <h2 id="scientific"><q>&hellip; neither scientific nor indicative of expected performance&hellip;</h2>
    <p><em><q>&hellip; That having been said &hellip; on the current benchmarks, Rust already outperforms C++, which is a pretty big deal&hellip;</em>
    <p>No, we have to choose — 
    <p>- either we accept the "neither scientific nor indicative" dismissal and don't even consider "a pretty big deal";
    <p>- or we reject the "neither scientific nor indicative" dismissal and consider "a pretty big deal".
    <p>(What "scientific" is supposed to mean in this context is unexplained; it seems just to be used as a dismissal).
  </section>
  <section>
    <h2 id="representative"><q>&hellip; nor indicative of expected performance on real-world idiomatic code.</q></h2>
    <p>We've certainly not attempted to prove that these measurements, of a few tiny programs, are somehow representative of the performance of any real-world applications — <em>not known</em>.
    <p>(Why we should only care about "idiomatic code" is unexplained; it seems just to be used as a dismissal). 
  </section>
  <section>
    <h2 id="name-game"><q>There's a reason they call it <q>a game</q>&hellip;</q></h2>
    <p>Not really. The name "benchmarks game" signifies nothing more than the fact that programmers contribute programs that compete (but try to remain comparable) for fun not money.
  </section>
  <section>
    <h2 id="dispute"><q>&hellip;to dispute a decision you basically need to pray the maintainer reopens it for some reason.</q></h2>
    <p>Never true. Followup comments could always be made in the project ticket tracker. There was a public discussion forum, etc. etc.
    <p>Someone's <q>brilliant hack</q> was rejected. Someone saw the opportunity to push traffic to their personal blog.
  </section>
  <section>
    <h2 id="maintenance-burden"><q>The guy that runs it arbitrarily decided to stop tracking some languages he didn't care about&hellip;</q></h2>
    <p>The guy that runs it arbitrarily decided to <b>start</b> tracking those languages he supposedly didn't care about.
    <p>Measurements are no longer made for these —
    <p>ATS, FreeBASIC, CINT, Cyclone, Intel C, Tiny C, Mono C#, Mono F#, Intel C++, CAL, Clean, Clojure, Digital Mars D, GNU D, Gwydion Dylan, SmartEiffel, bigForth, GNU GForth, G95 Fortran, Groovy, Hack, Icon, Io, Java -client, Java -Xint, gcj Java, Rhino JavaScript, SpiderMonkey, TraceMonkey, Lisaac, LuaJIT, Mercury, Mozart/Oz, Nice, Oberon-2, Objective-C, Pike, SWI Prolog, YAP Prolog, IronPython, PyPy, Rebol, Rexx, Scala, Bigloo Scheme, Chicken Scheme, Ikarus Scheme, GNU Smalltalk, Squeak Smalltalk, Mlton SML, SML/NJ, Tcl, Zonnon.
    <p>I know it will take more time than I choose. Been there; done that.
  </section>
  <h1 id="curious">Be curious</h1>
  <section>
    <h2 id="jvm-startup-time"><q>Wtf kind of benchmark counts the jvm startup time?</q></h2>
    <p>How much difference does it make for these particular tiny programs?
    <p>Compare the times against [pdf] <a href="https://shipilev.net/talks/devoxx-Nov2013-benchmarking.pdf">Java Microbenchmark Harness</a> reports:
    <table>
      <tr>
        <th>
        <th>secs
        <th>JMH Average
      <tr>
        <td>n-body
        <td>21.54
        <td>23.367 ± 0.062
      <tr>
        <td>spectral-norm
        <td>4.29
        <td>4.061 ± 0.054
      <tr>
        <td>meteor-contest
        <td>0.24
        <td>0.112 ± 0.001
    </table>
    <p><em>otoh</em> JVM start-up, JIT, OSR&hellip; are quickly effective and typical cold / warmed-up comparison at most of these workloads will show miniscule difference.
    <p><em>otoh</em> For measurements of a few tenths of a second, a few tenths of a second is a huge difference.
    <p>(<q>In stark contrast to the traditional expectation of <q>warmup</q>, some benchmarks exhibit <a href="https://tratt.net/laurie/blog/entries/why_arent_more_users_more_happy_with_our_vms_part_1.html"><q>slowdown</q></a>, where the performance of in-process iterations drops over time.</q>)
  </section>
</article>
<footer>
</footer>
